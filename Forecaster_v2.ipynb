{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GXNor1FSBJQe"
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import  plotly.express as px \n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#Read US Covid deaths abd filter LA county \n",
    "US_Deaths_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv'\n",
    "US_Deaths_df = pd.read_csv(US_Deaths_url, error_bad_lines=True)\n",
    "US_Deaths_df=US_Deaths_df.drop(columns=['UID','iso2','iso3','code3','Admin2', 'Country_Region','Lat','Long_','Combined_Key'])\n",
    "US_Deaths_df=US_Deaths_df.dropna(subset=['FIPS'])\n",
    "US_Deaths_df=US_Deaths_df.melt(id_vars=[\"FIPS\",\"Population\",\"Province_State\"], \n",
    "        var_name=\"Date\", \n",
    "        value_name=\"Value\")\n",
    "\n",
    "#Read US Covid cases\n",
    "Confirmed_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'\n",
    "US_Cases_df = pd.read_csv(Confirmed_url, error_bad_lines=True)\n",
    "US_Cases_df=US_Cases_df.drop(columns=['UID','iso2','iso3','code3','Admin2', 'Province_State', 'Country_Region','Lat','Long_','Combined_Key'])\n",
    "US_Cases_df=US_Cases_df.dropna(subset=['FIPS'])\n",
    "US_Cases_df=US_Cases_df.melt(id_vars=['FIPS'], \n",
    "        var_name=\"Date\", \n",
    "        value_name=\"Value\")\n",
    "\n",
    "\n",
    "US_Deaths_df.iloc[:, 3] = pd.to_datetime(US_Deaths_df.iloc[:, 3])\n",
    "US_Deaths_df.iloc[:, 3]  = (US_Deaths_df.iloc[:, 3]  - US_Deaths_df['Date'].iloc[0]).dt.days\n",
    "US_Deaths_df = US_Deaths_df.rename(columns={'Date': 'Days', 'Value':'Cumulative_Deaths' })\n",
    "\n",
    "#US_Deaths_df['Weekly_Deaths'] = US_Deaths_df.groupby(['FIPS', 'Week'])['Cumulative_Deaths'].transform(lambda x: (x.iat[-1] - x.iat[0]))\n",
    "US_Deaths_df['Weekly_Deaths'] = 0\n",
    "US_Deaths_df['Weekly_Deaths_Per'] = 0.0\n",
    "US_Deaths_df['Past_Week_Cumulative_Deaths'] = 0\n",
    "US_Deaths_df = US_Deaths_df.reset_index()\n",
    "US_Deaths_df.sort_values(by=['FIPS','Days'], inplace=True)\n",
    "cdArray = US_Deaths_df['Cumulative_Deaths'].to_numpy()\n",
    "fipsArray = US_Deaths_df['FIPS'].to_numpy()\n",
    "i =0\n",
    " \n",
    "for index, row in US_Deaths_df.iterrows():\n",
    "  stateFIPS = row['FIPS']\n",
    "  if i > 7 and FIPS == stateFIPS and fipsArray[i-7] == FIPS :\n",
    "    previous_cum_deaths = cdArray[i-7]\n",
    "    weekly_deaths = row['Cumulative_Deaths'] - previous_cum_deaths\n",
    "    US_Deaths_df.at[index,'Weekly_Deaths'] =  weekly_deaths\n",
    "    if previous_cum_deaths  == 0:\n",
    "      previous_cum_deaths = 1\n",
    "    US_Deaths_df.at[index, 'Past_Week_Cumulative_Deaths'] = previous_cum_deaths\n",
    "    US_Deaths_df.at[index, 'Weekly_Deaths_Per'] = (weekly_deaths * 1.0) / (previous_cum_deaths * 1.0)\n",
    "  else:\n",
    "    FIPS = stateFIPS  \n",
    "    US_Deaths_df.at[index,'Weekly_Deaths'] = row['Cumulative_Deaths']\n",
    "  i = i + 1\n",
    " \n",
    "US_Cases_df.iloc[:, 1] = pd.to_datetime(US_Cases_df.iloc[:, 1])\n",
    "US_Cases_df.iloc[:, 1]  = (US_Cases_df.iloc[:, 1]  - US_Cases_df['Date'].iloc[0]).dt.days\n",
    "US_Cases_df = US_Cases_df.rename(columns={'Date': 'Days', 'Value':'Cumulative_Cases'})\n",
    "US_Cases_df['Weekly_Cases'] = 0\n",
    "US_Cases_df['Weekly_Cases_Per'] = 0.0\n",
    "US_Cases_df = US_Cases_df.reset_index()\n",
    "US_Cases_df.sort_values(by=['FIPS','Days'], inplace=True)\n",
    "cdArray = US_Cases_df['Cumulative_Cases'].to_numpy()\n",
    "fipsArray = US_Cases_df['FIPS'].to_numpy()\n",
    "i =0\n",
    " \n",
    "for index, row in US_Cases_df.iterrows():\n",
    "  stateFIPS = row['FIPS']\n",
    "  if i > 7 and FIPS == stateFIPS and fipsArray[i-7] == FIPS :\n",
    "    previous_cum_cases = cdArray[i-7]\n",
    "    weekly_cases = row['Cumulative_Cases'] - previous_cum_cases\n",
    "    US_Cases_df.at[index,'Weekly_Cases'] =  weekly_cases\n",
    "    if previous_cum_cases  == 0:\n",
    "      previous_cum_cases = 1\n",
    "    US_Cases_df.at[index, 'Weekly_Cases_Per'] = (weekly_cases * 1.0) / (previous_cum_cases * 1.0)\n",
    "  else:\n",
    "    FIPS = stateFIPS  \n",
    "    US_Cases_df.at[index,'Weekly_Cases'] = row['Cumulative_Cases']\n",
    "  i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RvHB7ubQ8LjS"
   },
   "outputs": [],
   "source": [
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kjOaGxmUwynr"
   },
   "outputs": [],
   "source": [
    "#load state tests data to combine with cases and deaths\n",
    "#data is not available for all days, populate zero for missing ones\n",
    "from datetime import timedelta, date\n",
    "\n",
    "state_codes = pd.read_csv('https://docs.google.com/spreadsheets/d/1DAqxIYJdagFN85ncoTQO-CbpJLQECvZWt6qwNMQZUkk/export?format=csv')\n",
    "start_date = date(2020, 1, 22)\n",
    "end_date = date.today()\n",
    "\n",
    "state_codes_date_df = pd.DataFrame({'Date': pd.Series([], dtype='str'),\n",
    "                   'Code': pd.Series([], dtype='str'),\n",
    "                   'State': pd.Series([], dtype='str')})\n",
    "for single_date in daterange(start_date, end_date):\n",
    "  for index, row in state_codes.iterrows():\n",
    "    state_codes_date_df = state_codes_date_df.append({'Date': single_date.strftime(\"%Y%m%d\"), 'Code' : row[\"Code\"], 'State' : row[\"State\"]}, ignore_index=True)\n",
    "state_tests = pd.read_csv(\"https://covidtracking.com/api/v1/states/daily.csv\")\n",
    "convert_dict = {'date': str} \n",
    "state_tests = state_tests.astype(convert_dict)\n",
    "state_tests_df = state_codes_date_df.merge(state_tests[['date','state','positive', 'negative']],how='left', left_on=['Date', 'Code'], right_on=['date', 'state'])\n",
    "state_tests_df.sort_values(['Date','State'], inplace=True)\n",
    "state_tests_df.iloc[:, 0] = pd.to_datetime(state_tests_df.iloc[:, 0],format=\"%Y%m%d\")\n",
    "state_tests_df.iloc[:, 0]  = (state_tests_df.iloc[:, 0] - state_tests_df['Date'].iloc[0]).dt.days\n",
    "state_tests_df = state_tests_df.rename(columns={'Date': 'Days'})\n",
    "state_tests_df['Cumulative_Tests'] = state_tests_df['positive'] + state_tests_df ['negative']\n",
    "state_tests_df = state_tests_df.drop(columns=['date', 'state', 'positive', 'negative'])\n",
    "state_tests_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21GaGHXZT8M2"
   },
   "outputs": [],
   "source": [
    "#Read county variates dataset and combine with FIPS, race, icu_beds dataset\n",
    "county_covariates= pd.read_csv('https://raw.githubusercontent.com/JieYingWu/COVID-19_US_County-level_Summaries/master/data/counties.csv').dropna(subset=['FIPS'])\n",
    "county_covariates.FIPS = county_covariates.FIPS.astype('int64')\n",
    "county_covariates=county_covariates.set_index('FIPS')\n",
    "age_race_df = pd.read_csv('https://docs.google.com/spreadsheets/d/12GIRONjeNHeKFb3EKpo5r-VvdsnTwwe0iOtKBsnZVM0/export?format=csv')\n",
    "county_icu_beds= pd.read_csv('https://docs.google.com/spreadsheets/d/13iUBUwRcE91_x9FhsF8Ugcb0_tFauWJF2Z-PSkERDlU/export?format=csv')\n",
    "FIPS = pd.read_csv('https://docs.google.com/spreadsheets/d/1jUwRaTSJ__3Wp60cZLLox5u55mJTZrShtjEK4d7xTEY/export?format=csv')\n",
    "covariates = age_race_df.merge(county_covariates, how='inner', left_on=[\"fips\"], right_on=['FIPS'])\n",
    "covariates = covariates.drop(['STNAME', 'County', 'Unnamed: 0','State', 'Area_Name'], axis=1)\n",
    "covariates = covariates.merge(county_icu_beds, how='inner', left_on=[\"fips\"], right_on=['fips'])\n",
    "covariates = covariates.drop(['County','State'], axis=1)\n",
    "#dropping full NaN counties\n",
    "covariates = covariates[covariates['Jul Temp Max / F'].notnull()]\n",
    "#merge with US FIPS and makue  sure FIPS are only in the US\n",
    "US_Deaths_df = US_Deaths_df.merge(FIPS,how='inner', left_on=[\"FIPS\"], right_on=['fips'])\n",
    "US_Cases_df = US_Cases_df.merge(FIPS,how='inner', left_on=[\"FIPS\"], right_on=['fips'])\n",
    "list(covariates.columns) \n",
    "covariates = covariates.dropna(axis='columns')\n",
    "list(covariates.columns) \n",
    "\n",
    "covariates=covariates[['fips',\n",
    " 'TOT_POP',\n",
    " '0-9',\n",
    " '0-9 y/o % of total pop',\n",
    " '10-19',\n",
    " '10-19 y/o % of total pop',\n",
    " '20-29',\n",
    " '20-29 y/o % of total pop',\n",
    " '30-39',\n",
    " '30-39 y/o % of total pop',\n",
    " '40-49',\n",
    " '40-49 y/o % of total pop',\n",
    " '50-59',\n",
    " '50-59 y/o % of total pop',\n",
    " '60-69',\n",
    " '60-69 y/o % of total pop',\n",
    " '70-79',\n",
    " '70-79 y/o % of total pop',\n",
    " '80+',\n",
    " '80+ y/o % of total pop',\n",
    " 'White-alone pop',\n",
    " '% White-alone',\n",
    " 'Black-alone pop',\n",
    " '% Black-alone',\n",
    " 'Native American/American Indian-alone pop',\n",
    " '% NA/AI-alone',\n",
    " 'Asian-alone pop',\n",
    " '% Asian-alone',\n",
    " 'Hawaiian/Pacific Islander-alone pop',\n",
    " '% Hawaiian/PI-alone',\n",
    " 'Two or more races pop',\n",
    " '% Two or more races',\n",
    " 'POP_ESTIMATE_2018',\n",
    " 'N_POP_CHG_2018',\n",
    " 'GQ_ESTIMATES_2018',\n",
    " 'R_birth_2018',\n",
    " 'R_death_2018',\n",
    " 'R_NATURAL_INC_2018',\n",
    " 'R_INTERNATIONAL_MIG_2018',\n",
    " 'R_DOMESTIC_MIG_2018',\n",
    " 'R_NET_MIG_2018',\n",
    " 'Less than a high school diploma 2014-18',\n",
    " 'High school diploma only 2014-18',\n",
    " \"Some college or associate's degree 2014-18\",\n",
    " \"Bachelor's degree or higher 2014-18\",\n",
    " 'Percent of adults with less than a high school diploma 2014-18',\n",
    " 'Percent of adults with a high school diploma only 2014-18',\n",
    " \"Percent of adults completing some college or associate's degree 2014-18\",\n",
    " \"Percent of adults with a bachelor's degree or higher 2014-18\",\n",
    " 'POVALL_2018',\n",
    " 'PCTPOVALL_2018',\n",
    " 'PCTPOV017_2018',\n",
    " 'PCTPOV517_2018',\n",
    " 'MEDHHINC_2018',\n",
    " 'CI90LBINC_2018',\n",
    " 'CI90UBINC_2018',\n",
    " 'Civilian_labor_force_2018',\n",
    " 'Employed_2018',\n",
    " 'Unemployed_2018',\n",
    " 'Unemployment_rate_2018',\n",
    " 'Median_Household_Income_2018',\n",
    " 'Med_HH_Income_Percent_of_State_Total_2018',\n",
    " 'Jan Precipitation / inch',\n",
    " 'Feb Precipitation / inch',\n",
    " 'Mar Precipitation / inch',\n",
    " 'Apr Precipitation / inch',\n",
    " 'May Precipitation / inch',\n",
    " 'Jun Precipitation / inch',\n",
    " 'Jul Precipitation / inch',\n",
    " 'Jan Temp AVG / F',\n",
    " 'Feb Temp AVG / F',\n",
    " 'Mar Temp AVG / F',\n",
    " 'Apr Temp AVG / F',\n",
    " 'May Temp AVG / F',\n",
    " 'Jun Temp AVG / F',\n",
    " 'Jul Temp AVG / F',\n",
    " 'Active Physicians per 100000 Population 2018 (AAMC)',\n",
    " 'Total Active Patient Care Physicians per 100000 Population 2018 (AAMC)',\n",
    " 'Active Primary Care Physicians per 100000 Population 2018 (AAMC)',\n",
    " 'Active Patient Care Primary Care Physicians per 100000 Population 2018 (AAMC)',\n",
    " 'Active General Surgeons per 100000 Population 2018 (AAMC)',\n",
    " 'Active Patient Care General Surgeons per 100000 Population 2018 (AAMC)',\n",
    " 'Total nurse practitioners (2019)',\n",
    " 'Total physician assistants (2019)',\n",
    " 'Total Hospitals (2019)',\n",
    " 'Internal Medicine Primary Care (2019)',\n",
    " 'Family Medicine/General Practice Primary Care (2019)',\n",
    " 'Total Specialist Physicians (2019)',\n",
    " 'ICU Beds_x',\n",
    " 'Total Population',\n",
    " 'Population Aged 60+',\n",
    " 'Percent of Population Aged 60+']]\n",
    " \n",
    "#print(covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VF6n1wU4ynx3"
   },
   "outputs": [],
   "source": [
    "#merge us covid deaths and cases with covariates\n",
    "\n",
    "US_Deaths_Cases_df = US_Deaths_df.merge(US_Cases_df[['Cumulative_Cases', 'Weekly_Cases', 'FIPS', 'Days']], how='inner', left_on=['FIPS', \"Days\"], right_on=['FIPS', 'Days'])\n",
    "US_Deaths_Cases_df = US_Deaths_Cases_df.merge(state_tests_df, how='inner', left_on=['Province_State', \"Days\"], right_on=['State', 'Days'])\n",
    "covariates_merged = covariates.merge(US_Deaths_Cases_df[['Cumulative_Tests','Cumulative_Cases', 'Weekly_Cases', 'FIPS', 'Days']], how='inner', left_on=[\"fips\"], right_on=['FIPS'])\n",
    "#dropping NaN columns\n",
    "covariate_merged = covariates_merged.dropna(axis='columns')\n",
    "US_Deaths_Cases_df =  US_Deaths_Cases_df.dropna(axis='columns')\n",
    "fips_state=age_race_df[['STNAME','fips']]\n",
    "US_Deaths_Cases_df = US_Deaths_Cases_df.merge(fips_state, how='inner', left_on=[\"FIPS\"], right_on=['fips'])\n",
    "US_Deaths_Cases_df = US_Deaths_Cases_df.drop(columns=['index'])\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#corr=covariate_merged.corr()\n",
    "#print(corr[['Cumulative_Deaths','Daily_Deaths']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "xseYJzjKY8FK",
    "outputId": "c77e79f3-b0e5-4328-ffca-afbd3fa0cb6e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "US_Deaths_Cases_df\n",
    "Deaths_Cases_df = US_Deaths_Cases_df[(US_Deaths_Cases_df[\"FIPS\"] == 4015.0) & (US_Deaths_Cases_df[\"Days\"] > 90)]\n",
    "\n",
    "x = Deaths_Cases_df[\"Days\"]\n",
    "y = Deaths_Cases_df[\"Cumulative_Deaths\"]\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "y = Deaths_Cases_df[\"Weekly_Deaths\"]\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "y = Deaths_Cases_df[\"Weekly_Deaths_Per\"]\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "WghtKSQ6xAYp",
    "outputId": "8b2721d6-8f6d-4812-84ef-7592ea4dda37"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import MultiTaskLassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "covid_start_date = datetime.strptime(\"01/22/20\", \"%m/%d/%y\")\n",
    "\n",
    "min_day=US_Deaths_Cases_df['Days'].min()\n",
    "max_day=US_Deaths_Cases_df['Days'].max()\n",
    "countyFIPS = US_Deaths_Cases_df[\"FIPS\"].unique()\n",
    "\n",
    "num_weeks=int((max_day-min_day)/7)\n",
    "print(\"number of weeks : \" , num_weeks)\n",
    "#prediction_days = 7   # one week  train , tune and forecast\n",
    "prediction_days = 14 # two weks train , tune and forecast\n",
    "#prediction_days = 14 # three weks train , tune and forecast\n",
    "#prediction_days = 28 # four weeks train , tune and forecast\n",
    "day_offset=68\n",
    "\n",
    "\n",
    "predicted_df_all_days = pd.DataFrame(columns=['State','FIPS', 'Forecast_Day','Days','Predicted_Weekly_Deaths' 'Predicted_Cumulative_Deaths'])\n",
    "#i = 0\n",
    "#iteration = 0 \n",
    "#index = 0\n",
    "#tune_forecast_rscores = pd.DataFrame( columns=['week', 'tune_alpha', 'tune_max_r2_score', 'forecast_r2_score'])\n",
    "#weekly_alpha_rscores = pd.DataFrame( columns=['week', 'alpha', 'r2_score'])\n",
    "#predict_week_rscores = pd.DataFrame( columns=['week', 'r2_score'])\n",
    "\n",
    "train_start_week_day = day_offset\n",
    "train_end_week_day = train_start_week_day + prediction_days\n",
    "tune_start_week_day = train_end_week_day\n",
    "tune_end_week_day = train_end_week_day + prediction_days\n",
    "predict_start_week_day = tune_end_week_day \n",
    "predict_end_week_day = tune_end_week_day + prediction_days\n",
    "\n",
    "\n",
    "for week_num in range(num_weeks):\n",
    "  if tune_end_week_day > max_day:\n",
    "    break\n",
    "  print(\"train:\", train_start_week_day ,\":\", train_end_week_day, \" tune:\",  tune_start_week_day,\":\", tune_end_week_day,\n",
    "        \" predict:\" , predict_start_week_day, \":\",  predict_end_week_day)\n",
    "  #print (\"training week number: \" , week_num+1)\n",
    "#********************TRAIN MODEL ************************ \n",
    "#train with all coutnies variates for one  week  and predict for LA county cumulative deaths\n",
    "  train_week = pd.Series(range(train_start_week_day,train_end_week_day))\n",
    "  #print (\"training week series :\" , train_week.array)\n",
    "  covariates_train_week = covariates_merged.loc[(covariates_merged['Days'].isin(train_week))] \n",
    "  US_Weekly_Deaths = US_Deaths_Cases_df.loc[(US_Deaths_Cases_df['Days'].isin(train_week))].iloc[:, 5]  \n",
    "  if len(US_Weekly_Deaths) == 0:\n",
    "    continue\n",
    "  alphas = [.0001,0.001, 0.01, 0.1]\n",
    "\n",
    "  #train and predict the future week for LA County\n",
    "  tune_week = pd.Series(range(tune_start_week_day, tune_end_week_day ))\n",
    "  #print (\"tune next week series :\" , tune_week.array)\n",
    "\n",
    "  alpha_with_max_r2score = -1\n",
    "  max_r2score = -10\n",
    "  best_reg = None\n",
    "\n",
    "  #********************VALIDATE MODEL ************************ \n",
    "  #test next week/weeks data for various alpha and pick the one with max r score.\n",
    "  for alpha in alphas:\n",
    "    X_train = covariates_train_week\n",
    "    Y_train = US_Weekly_Deaths\n",
    "    #reg = LassoCV(cv=5, random_state=0).fit(X_train, Y_train)\n",
    "    #reg = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42, alpha=alpha)\n",
    "    reg = xgb.XGBRegressor(learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='reg:squarederror', random_state=0,\n",
    "       reg_alpha=alpha, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=None, subsample=1, verbosity=1)\n",
    "    reg.fit(X_train, Y_train)\n",
    "    #reg = ElasticNet(alpha=alpha).fit(X_train, Y_train)\n",
    "    \n",
    "    X_tune_week = covariates_merged.loc[(covariates_merged['Days'].isin(tune_week))]\n",
    "    Y_actual_tune_week = US_Deaths_Cases_df.loc[(US_Deaths_Cases_df['Days'].isin(tune_week))].iloc[:, 5]\n",
    "    #score = reg.score(X_tune_week, Y_actual_tune_week)\n",
    "    reg.fit(X_tune_week, Y_actual_tune_week)\n",
    "    Y_tune_week = reg.predict(X_tune_week)\n",
    "    score = r2_score(Y_actual_tune_week, Y_tune_week)\n",
    "    #weekly_alpha_rscores.loc[index] = [week_num, alpha,score]\n",
    "    #index = index + 1\n",
    "    if score > max_r2score:\n",
    "      max_r2score = score\n",
    "      alpha_with_max_r2score = alpha\n",
    "      best_reg = reg\n",
    "\n",
    "  #iteration = iteration + 1\n",
    "  \n",
    "  #********************FORECAST FUTURE USING MODEL ************************ \n",
    "  # take the regression with best r score and predict nex week\n",
    "  if best_reg:\n",
    "    predict_week = pd.Series(range(predict_start_week_day, predict_end_week_day ))\n",
    "    #print (\"predicting next week series :\" , predict_week.array)\n",
    "  \n",
    "    X_predict_week = covariates_merged.loc[(covariates_merged['Days'].isin(predict_week))]\n",
    "    predict_week_df = US_Deaths_Cases_df.loc[(US_Deaths_Cases_df['Days'].isin(predict_week))]\n",
    "    Y_actual_predict_week = predict_week_df.iloc[:,5]\n",
    "    best_reg.fit(X_tune_week, Y_actual_tune_week)\n",
    "    Y_predict_week = best_reg.predict(X_predict_week)\n",
    "    predict_score = r2_score(Y_actual_predict_week, Y_predict_week)\n",
    "  \n",
    "    predicted_df = pd.DataFrame(columns=['State','FIPS', 'Forecast_Day','Days','Predicted_Weekly_Deaths','Predicted_Cumulative_Deaths'])\n",
    "    predicted_df[\"State\"] = predict_week_df[\"STNAME\"]\n",
    "    predicted_df[\"FIPS\"] = predict_week_df[\"FIPS\"]\n",
    "    predicted_df[\"Days\"] = predict_week_df[\"Days\"]\n",
    "    predicted_df[\"Forecast_Day\"] =  (covid_start_date + timedelta(days=(predict_start_week_day-1))).strftime(\"%Y-%m-%d\")\n",
    "    predicted_df[\"Predicted_Weekly_Deaths\"] = Y_predict_week\n",
    "    predicted_df[\"Predicted_Cumulative_Deaths\"] = predicted_df[\"Predicted_Weekly_Deaths\"]  + predict_week_df[\"Past_Week_Cumulative_Deaths\"]\n",
    "    predicted_df_all_days = pd.concat([predicted_df_all_days, predicted_df])\n",
    "\n",
    "    print(week_num , \":\",  alpha_with_max_r2score , \":\", max_r2score, \":\", predict_score)\n",
    "  \n",
    "    #tune_forecast_rscores.loc[iteration] = [week_num,alpha_with_max_r2score,  max_r2score, predict_score]\n",
    "    #predict_week_rscores.loc[iteration] = [week_num,  predict_score]m\n",
    "\n",
    "  #start_week_day = start_week_day + 14\n",
    " \n",
    "  train_start_week_day = train_start_week_day + prediction_days\n",
    "  train_end_week_day = train_end_week_day + prediction_days\n",
    "  tune_start_week_day = train_end_week_day\n",
    "  tune_end_week_day = tune_end_week_day + prediction_days\n",
    "  predict_start_week_day = tune_end_week_day\n",
    "  predict_end_week_day = predict_end_week_day + prediction_days\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "AF_-wov9jpEE",
    "outputId": "3a8acbc9-57f7-4e47-9503-99aa97de40c0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "Deaths_Cases_df = US_Deaths_Cases_df[(US_Deaths_Cases_df[\"FIPS\"] == 24031.0) & (US_Deaths_Cases_df[\"Days\"] > 96) & (US_Deaths_Cases_df[\"Days\"] < 166)]\n",
    "predicted_df_90 = predicted_df_all_days[(predicted_df_all_days[\"FIPS\"] == 24031.0) & (predicted_df_all_days[\"Days\"] > 96) & (predicted_df_all_days[\"Days\"] < 166)]\n",
    "x = Deaths_Cases_df[\"Days\"]\n",
    "z= predicted_df_90[\"Predicted_Cumulative_Deaths\"]\n",
    "y = Deaths_Cases_df[\"Cumulative_Deaths\"]\n",
    "plt.title(\"Cumulative Deaths - Pred vs Actual\")\n",
    "plt.plot(x, y, \"-b\", label=\"actual\")\n",
    "\n",
    "plt.plot(x, z, \"-r\", label=\"predicted\")\n",
    "plt.show()\n",
    "\n",
    "x = Deaths_Cases_df[\"Days\"]\n",
    "z= predicted_df_90[\"Predicted_Weekly_Deaths\"]\n",
    "y = Deaths_Cases_df[\"Weekly_Deaths\"]\n",
    "plt.title(\"Weekly Deaths - Pred vs Actual\")\n",
    "plt.plot(x, y, \"-b\", label=\"actual\")\n",
    "plt.plot(x, z, \"-r\", label=\"predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "S7woMnPEfGvn",
    "outputId": "2c83fed8-edf8-439a-aa78-b21440f8a386"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from google.colab import files\n",
    "\n",
    "covid_start_date = datetime.strptime(\"01/22/20\", \"%m/%d/%y\")\n",
    "\n",
    "state_predicted_deaths = predicted_df_all_days.groupby(['State', 'Days', 'Forecast_Day'], as_index=False)[[\"Predicted_Cumulative_Deaths\"]].sum()\n",
    "state_to_fips=pd.read_csv('https://docs.google.com/spreadsheets/d/1w4sHgYifJV-C8J1WV5rpTzEFLuyZ5ESp8r_1ck-9hlA/export?format=csv')\n",
    "state_predicted_deaths = state_predicted_deaths.merge(state_to_fips, how='left', left_on=['State'], right_on=['Name'])\n",
    "state_predicted_deaths=state_predicted_deaths.drop(columns=['Name'])\n",
    "country_predicted_deaths = predicted_df_all_days.groupby(['Days', 'Forecast_Day'], as_index=False)[[\"Predicted_Cumulative_Deaths\"]].sum()\n",
    "\n",
    "state_predicted_deaths=state_predicted_deaths[['State','FIPS','Days','Forecast_Day','Predicted_Cumulative_Deaths']]\n",
    "covid_hub_predicted_deaths = pd.DataFrame(columns=['forecast_date','target', 'target_end_date','location', 'location_name','type', 'quantile', 'value'])\n",
    "iteration = 0  \n",
    "forecast_dates = country_predicted_deaths[\"Forecast_Day\"].unique()\n",
    "for forecast_date in forecast_dates:\n",
    "  print(forecast_date)\n",
    "  filename = \"data_processed/{}-MIT-Sak.csv\".format(forecast_date)\n",
    "  cp_detahs_forecast= country_predicted_deaths[country_predicted_deaths[\"Forecast_Day\"] == forecast_date]\n",
    "  for index, row in cp_detahs_forecast.iterrows():\n",
    "\n",
    "      covid_hub_predicted_deaths.loc[iteration,\"location\"] = 'US'\n",
    "      covid_hub_predicted_deaths.loc[iteration,\"location_name\"] = 'US'\n",
    "      #predicted_df[\"FIPS\"] = predict_week_df[\"FIPS\"]\n",
    "      #predicted_df[\"Days\"] = predict_week_df[\"Days\"]\n",
    "      target_date = (covid_start_date + timedelta(days=row[\"Days\"]))\n",
    "      forecast_day =  (datetime.strptime(row[\"Forecast_Day\"],\"%Y-%m-%d\") - covid_start_date).days\n",
    "      days_from = str(row[\"Days\"] - forecast_day)\n",
    "      covid_hub_predicted_deaths.loc[iteration,\"target\"] = days_from + \" day ahead cum death\"\n",
    "      covid_hub_predicted_deaths.loc[iteration,\"target_end_date\"] = target_date.strftime(\"%Y-%m-%d\")\n",
    "      covid_hub_predicted_deaths.loc[iteration,\"forecast_date\"] =  row[\"Forecast_Day\"]\n",
    "      covid_hub_predicted_deaths.loc[iteration,\"type\"] =\"point\"\n",
    "      covid_hub_predicted_deaths.loc[iteration,\"quantile\"] =\"NA\"\n",
    "      if row[\"Predicted_Cumulative_Deaths\"] >= 0:\n",
    "        covid_hub_predicted_deaths.loc[iteration,\"value\"] = row[\"Predicted_Cumulative_Deaths\"]\n",
    "      else:\n",
    "        covid_hub_predicted_deaths.loc[iteration,\"value\"] = 0\n",
    "\n",
    "      iteration = iteration + 1\n",
    "  state_predicted_deaths_forecast = state_predicted_deaths[state_predicted_deaths[\"Forecast_Day\"] == forecast_date]\n",
    "  for index, row in state_predicted_deaths_forecast.iterrows():\n",
    "      covid_hub_predicted_deaths.loc[iteration,\"location\"] = str(row[\"FIPS\"]).zfill(2)\n",
    "      covid_hub_predicted_deaths.loc[iteration,\"location_name\"] = row[\"State\"]\n",
    "   \n",
    "      target_date = (covid_start_date + timedelta(days=row[\"Days\"]))\n",
    "      forecast_day =  (datetime.strptime(row[\"Forecast_Day\"],\"%Y-%m-%d\") - covid_start_date).days\n",
    "      days_from = str(row[\"Days\"] - forecast_day)\n",
    "   \n",
    "      covid_hub_predicted_deaths.loc[iteration,\"target\"] = days_from + \" day ahead cum death\"\n",
    "      covid_hub_predicted_deaths.loc[iteration,\"target_end_date\"] = target_date.strftime(\"%Y-%m-%d\")\n",
    "      covid_hub_predicted_deaths.loc[iteration,\"forecast_date\"] =  row[\"Forecast_Day\"]\n",
    "      covid_hub_predicted_deaths.loc[iteration,\"type\"] =\"point\"\n",
    "      covid_hub_predicted_deaths.loc[iteration,\"quantile\"] =\"NA\"\n",
    "      if row[\"Predicted_Cumulative_Deaths\"] >= 0:\n",
    "        covid_hub_predicted_deaths.loc[iteration,\"value\"] = row[\"Predicted_Cumulative_Deaths\"]\n",
    "      else:\n",
    "        covid_hub_predicted_deaths.loc[iteration,\"value\"] = 0\n",
    "      iteration = iteration + 1\n",
    "  \n",
    "  covid_hub_predicted_deaths.to_csv(filename,index = False)\n",
    "  #files.download(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Forecaster v2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
